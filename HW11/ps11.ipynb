{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8b74a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps11.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a19c7",
   "metadata": {},
   "source": [
    "# Problem Set 11\n",
    "## Logistic regression, automatic differentiation, and neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17142f",
   "metadata": {},
   "source": [
    "In this problem set you will study binary classification using logistic regression, and implement neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f3cca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f840c4b19d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "rng_seed = 507\n",
    "torch.manual_seed(rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c185eb1-917b-47a5-bfab-cc8fcd79019f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n, p = X.shape\n",
    "n, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc62c1d",
   "metadata": {},
   "source": [
    "## Question 1: Binary classification\n",
    "\n",
    "In this exercise you will use `sklearn` to build a binary classifier.\n",
    "\n",
    "Logistic regression assumes the probability model \n",
    "\n",
    "$$\\mathbb{P}(y_i=1\\mid \\mathbf{x}_i) = \\sigma(\\mathbf{x}_i^T\\boldsymbol{\\beta}),$$ \n",
    "\n",
    "where $\\mathbf{x}_i$ are rows of the data matrix $\\mathbf{X}\\in\\mathbb{R}^{n\\times p}$, $\\mathbf{y}\\in\\{0,1\\}^n$ is a vector of binary responses, and\n",
    "\n",
    "$$\\sigma(z)=\\frac{1}{1+\\exp(-z)}$$ \n",
    "\n",
    "is a *sigmoid* function which maps  real numbers into the interval $[0,1]$. \n",
    "\n",
    "In simple terms, a linear regression formula can be converted into a logistic regression by applying the sigmoid function. Using scikit-learn module, it gets very simple to apply these algorithms and that is what you will explore in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601676f4",
   "metadata": {},
   "source": [
    "The classifier will take as input a $28\\times 28$ grayscale MNIST image, and return `1` if the image represents the number 5, and `0` otherwise.\n",
    "\n",
    "*Note*: various algorithms implemented in `sklearn` are randomized. To utilize the same randomness as we did when generating the solutions (and hence, to ensure that your output passes the test cases), use `random_state=1` wherever necessary when calling `sklearn` methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f16323",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(a)** (1 pt) Using the `mnist` data loaded above, create a standardized version of `X` where each column has zero mean and variance one. (Hint: use the `sklearn.preprocessing` module.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6354a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stdscal = sklearn.preprocessing.StandardScaler()\n",
    "Xs = stdscal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb23a9bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/nbformat/__init__.py:92: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1a</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "1a results: All test cases passed!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390fcca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(b)** (1 pt) Using the `mnist` data loaded above, create a vector `y5` which equals `1` if the the corresponding MINST image equals is of the number 5, and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd43a276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y5 = (y==5).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb344c2e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1b</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "1b results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a53c6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(c)**(1pt) Using `sklearn.model_selection.train_test_split`, divide the data into 70% training data and 30% test data. To ensure that your output matches our tests, pass the option `random_state=1` into the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71242b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "                                    Xs, y5, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ee9a67-949d-4753-8c84-ef89ba4d955d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y5==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd6b197",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1c</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "1c results: All test cases passed!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91bb47",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1(d)**(2pt) Use `sklearn.linear_model.LogisticRegression` to train a binary classifier on the *training data only*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b30b1a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2726fef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/nbformat/__init__.py:92: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1d</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "1d results: All test cases passed!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf91cae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1(e)**(1pt) How accurate is your trained classifier on `X_train`/`y_train`?  Use confusion matrix. \n",
    "\n",
    "Refer: \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "* https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "Assign values to variables called TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd9f830-da11-4403-9c85-83956a99955c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "TN, FP, FN, TP = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf797bad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/nbformat/__init__.py:92: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1e</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "1e results: All test cases passed!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8081a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**1(f)**(2pt) The regularization parameter can be varied by setting `LogisticRegression(C=C)` , where `C` is the value of the regularization penalty. What happens to the test error that you computed in the previous step as you vary `C`? Can you find a setting of `C` that results in lower test error than the default value `C=1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f05cb",
   "metadata": {},
   "source": [
    "In this model, `C` is the inverse of regularization strength.   \n",
    "\n",
    "Smaller `C` (stronger regularization) helps prevent overfitting by penalizing large coefficients. However, too much regularization may lead to underfitting, where the model is too simple and doesn't capture the underlying patterns in the data. So test error might increase compared to the default `C=1` due to underfitting.      \n",
    "\n",
    "Larger `C` (weaker regularization) allows the model to fit the training data more closely. However, it may lead to overfitting, where the model captures noise in the training data that doesn't generalize well to new, unseen data. So test error might increase due to overfitting.        \n",
    "\n",
    "Finding the optimal value of `C` involves tuning it through techniques like cross-validation. We can try different values of `C` and evaluate the model's performance using a validation set or through cross-validation. Typically, we believe the value of C that results in the lowest error on the validation set will lead to a low test error.\n",
    "\n",
    "In practice, it's not guaranteed that there exists a setting of `C` that will always result in a lower test error than the default value of `C=1`. But utilizing the abovementioned method, it's very likely for us to find out such `C`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08c761",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ade45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(a)**(2pt) In this problem you will understand how to calculate derivatives using pytorch. \n",
    "**Note:** If you do not use pytorch tensors to solve these problems, hidden tests will fail.\n",
    "\n",
    "Create a function called get_grad that receives a floating point value for 'x' and returns the gradient of the function at the given input value of 'x':\n",
    "\n",
    "$$y = x^2 + 3x + 5$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475955e1-ace2-4582-be9f-23f0dbf733fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grad(x):\n",
    "    x = torch.tensor(x, dtype=torch.float, requires_grad=True)\n",
    "    y = x**2 + 3*x + 5\n",
    "    y.backward()\n",
    "    return(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ea6953",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2a</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "2a results: All test cases passed!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8df82b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(b)**(2pt) \n",
    "We now extend the previous concept and get partial derivatives when you have two variables applied to the below function\n",
    "$$ùëì(ùë¢,ùë£)=ùë£ùë¢+ùë¢^3$$\n",
    "\n",
    "Write a function 'get_grads' that takes in two floating point numbers corresponding to the two variables; u and v, and returns the gradients as a tuple with respect to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7433698-fd45-4f59-a047-4c57d6c1e38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_grads(u, v):\n",
    "    u = torch.tensor(u, dtype=torch.float, requires_grad=True)\n",
    "    v = torch.tensor(v, dtype=torch.float, requires_grad=True)\n",
    "    f = u*v + u**3\n",
    "    f.backward()\n",
    "    return (u.grad, v.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1101b3fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2b</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "2b results: All test cases passed!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064fc16",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(c)**(2pt) Extend the linear regression model from scratch shown in class by adding the bias 'b'\n",
    "The linear function would be\n",
    "\n",
    "$$y = w * x + b$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8fc6ca0-18a2-4a6a-b45f-9915e799958f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "f = 1 * X - 1\n",
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "w = torch.tensor(-10.0, requires_grad = True)\n",
    "b = torch.tensor(10.0, requires_grad = True)\n",
    "lr = 0.1\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17289f1d-291e-4ab0-b04d-982c8564f6c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def criterion(yhat, y):\n",
    "    return torch.mean((yhat - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96836799-595f-47dd-8d14-2bbe432de25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72fc7f2d-2c2b-40a2-b65f-80aad3dba90d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(epochs, X, Y, lr):\n",
    "    global w, b\n",
    "    optimizer = torch.optim.SGD([w,b], lr=lr)\n",
    "    for epoch in range (epochs):\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # calculate the loss per iteration\n",
    "        loss = criterion(Yhat, Y)\n",
    "\n",
    "        # store the loss at every iteration\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # backward pass: compute gradient \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        #with torch.no_grad():\n",
    "        #    w -= lr*w.grad\n",
    "        #    b -= lr*b.grad\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3190dd2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2c</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "2c results: All test cases passed!"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf3b3f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(d)**(2pt)\n",
    "In this problem, you will learn to use the deep learning framework PyTorch\n",
    "We'll be using the Fashion MNIST dataset, which consists of 28x28 images that could be 10 different articles of clothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d02cee4-5917-4274-9c63-aafad61977bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets as visiondata\n",
    "training_data = visiondata.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe06f0-6a62-483b-91e7-baa7efd38ae0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run this cell to view a random sample from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6513c11e-a701-4226-98e0-76c7346d0ca2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce890b9-9d59-4339-8a94-5efd98c3e131",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here are some helper functions used for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b46d794-762a-47bd-91f5-5d592949cf8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total/len(dataloader)}\")\n",
    "        \n",
    "    return loss_total/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec71d80b-0b42-4d93-8a90-8e9dd0932525",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_test_accuracy(model, transform_fn, test_dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in test_dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim = 0)\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "\n",
    "    accuracy = (y_true == y_pred).float().mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35044b3-7fe4-446f-b78b-07ef2c1dde78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "NN consists of an input layer, an activation function, and another output layer. Write a class called MultiClassNN that subclasses nn.Module. This module contains one attribute, net, which is an nn.Sequential object that is called on the .forward(x) method. Your task is to write the __init__() method to correctly construct net.\n",
    "\n",
    "For example, if num_features=784, num_hidden=256, num_classes=10:\n",
    "\n",
    ">>> mlp = MultiClassNN(28**2, 256, 10)\n",
    ">>> mlp.net\n",
    "\n",
    "Sequential(\n",
    "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
    "  (1): Sigmoid()\n",
    "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
    "  (3): LogSoftmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2544231a-cad3-4802-9fb4-88216c3303de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiClassNN(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_classes):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            num_features: The number of features in the input.\n",
    "            num_hidden: Number of hidden features in the hidden layer:\n",
    "            num_classes: Number of possible classes in the output\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features= num_hidden, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=num_hidden, out_features=num_classes, bias=True),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "345ca832",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2d</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "2d results: All test cases passed!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4978b23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2(e)**(1pt) \n",
    "Construct a `DataLoader` object of the Fashion MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e331cc46-e6ed-4f88-8813-a5d0adcf5d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7dc7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**2(f)** \n",
    "(3pt) Initialize a `MultiClassNN` object called `mlp` and train it using the `train_loop()` function given at the beginning of the assignment (do not modify the `train_loop()` function). We will test your  `mlp` object on unseen test data.\n",
    "\n",
    "Hints:\n",
    "-  You need to initialize a `torch.optim.Optimizer` object for gradient descent. The standard choice is `torch.optim.Adam` with a learning rate `1e-3`.\n",
    "-  You need to flatten the Fashion MNIST dataset to use within the `MultiClassNN`. This should be done with the `transform_fn` argument to `train_loop`. Try `nn.Flatten()`.\n",
    "-  The output of `MultiClassNN` are the log probabilities of each class. To test the accuracy of your model, you should use the negative log-likelihood loss, `nn.NLLLoss()`, as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82b8b4ab-2bcf-4441-9315-bea4443bb181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18537360186706472: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [02:24<00:00,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18537360186706472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MultiClassNN(28**2, 256, 10)\n",
    "mlp_optimizer = torch.optim.Adam(params=mlp.parameters(), lr=1e-3)\n",
    "transform_fn = nn.Flatten()\n",
    "loss_fn = nn.NLLLoss()\n",
    "num_epochs = 20\n",
    "loss_total = train_loop(mlp, transform_fn, loss_fn, mlp_optimizer,\n",
    "                        train_dataloader, num_epochs)\n",
    "print(loss_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42321e00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8879)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_dataloader = DataLoader(dataset=visiondata.FashionMNIST(\n",
    "                                            root=\"data\",\n",
    "                                            train=False,\n",
    "                                            download=True,\n",
    "                                            transform=ToTensor()\n",
    "                                        ),\n",
    "                             batch_size=batch_size, shuffle=False)\n",
    "\n",
    "mlp.train(False)\n",
    "transform_fn.train(False)\n",
    "loss_fn.train(False)\n",
    "\n",
    "print(calculate_test_accuracy(mlp, transform_fn, test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe63543",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e651a6d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    <p>\n",
       "                        Your submission has been exported. Click\n",
       "                        <a href=\"ps11_2023_11_30T03_00_18_952753.zip\" downloadzip_path target=\"_blank\">here</a> to download\n",
       "                        the zip file.\n",
       "                    </p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6295f",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "1a": {
     "name": "1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> m = Xs.mean(axis = 0)\n>>> sd = Xs.std(axis = 0)\n>>> assert sum(abs(m)) < 1e-10\n>>> assert np.all(np.logical_or(abs(sd - 1) < 1e-10, abs(sd - 0) < 1e-10))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1b": {
     "name": "1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> place = np.where(y5 == 1)[0]\n>>> assert len(place) == 182\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1c": {
     "name": "1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape[0] == 1257\n>>> assert y_train.shape[0] == 1257\n>>> assert X_test.shape[0] == 540\n>>> assert y_test.shape[0] == 540\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1d": {
     "name": "1d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sum(clf.predict(X_test)) == 47\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "1e": {
     "name": "1e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert TP == 45\n>>> assert TN == 491\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2a": {
     "name": "2a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_grad(3.0) == 9.0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2b": {
     "name": "2b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_grads(1.0, 1.0) == (4.0, 1.0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2c": {
     "name": "2c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> train_model(15, X, Y, 0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert w < 2\n>>> assert b < 1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2d": {
     "name": "2d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(MultiClassNN(2,2,2).net[0], torch.nn.modules.linear.Linear)\n>>> assert isinstance(MultiClassNN(2,2,2).net[1], torch.nn.modules.Sigmoid)\n>>> # HIDDEN\n>>> assert isinstance(MultiClassNN(2,2,2).net[2], torch.nn.modules.linear.Linear)\n>>> assert isinstance(MultiClassNN(2,2,2).net[3], torch.nn.modules.activation.LogSoftmax)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
