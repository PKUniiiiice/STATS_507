{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33cc1c31",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps10.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5450b",
   "metadata": {},
   "source": [
    "# PS10: Using RDD and DataFrame in PySpark\n",
    "\n",
    "In this problemset you will hone your skills working with both RDD and spark Dataframe. This problemset has no hidden tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4459687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import collections\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate();\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffa872",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "This problem concerns working with RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217e31b-f9b5-482a-92d6-4b819ed8dc7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Q1a (3 points)\n",
    "\n",
    "This problemset has a text file named 'mother_theresa.txt'. An RDD of the textfile is created for you. Your job is to count how many words have 'mother' in it. 'mother' could be the whole string or part of the string. It still get counted as long as the entire 'mother' appears in the string. You also have to count the other words under the key 'other'. \n",
    "\n",
    "Hint: You would be using a mix of `flatMap`, `map` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca1a3916-20a5-4c66-9956-46a6bc55d8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "rdd = sc.textFile('mother_theresa.txt')\n",
    "rdd_flat = rdd.flatMap(lambda line: line.split()).map(lambda w: w.lower())#.flatMap(lambda w: re.findall(r'\\b[a-zA-Z]+\\b', w))\n",
    "rdd_flat = rdd_flat.map(lambda w: ('mother', 1) if 'mother' in w else ('other', 1))\n",
    "result1 = rdd_flat.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "216ce375",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1a</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q1a results: All test cases passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0bed6-bf74-46c9-8844-09cc4cb27ec0",
   "metadata": {},
   "source": [
    "### Q1b (2 points)\n",
    "\n",
    "Using the same RDD, find the length of each line in the text file first and then add the length of all the lines and display the total length of all lines. You need to strip the line before finding the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4de71d99-1297-4d27-b4f4-047b282cd0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_length = total_length = rdd.map(lambda line: line.strip()).map(lambda line: len(line)).reduce(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b010c8fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1b</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q1b results: All test cases passed!"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a15f7-1a4d-4bf5-a43f-bc7defe6d211",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "This problem concerns working with PySpark Dataframe. We will revisit the cdc dataset from the last assignment. But this time we are using spark to do our analytics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d8bba-06ed-4eb9-9221-9b439da6d698",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Q2a (3 points)\n",
    "\n",
    "We will reuse the same query we built in the last problemset. Fortunitely spark dataframe works for the same pandas syntax!  Your job is to use this subquery and find the max datavalue for each unique locationabbr value. Display the first 10 datavalues in descending order\n",
    "\n",
    "Hint: One way to do that is to group by `locationabbr` and find the max datavalue with in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e11c530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.read.csv('us_chronic_disease_indicators.csv', header = True)\n",
    "\n",
    "# you can use this expression to get a subset of data\n",
    "df_subset = df[(~df['locationabbr'].isin(['US','PR', 'GU'])) &\n",
    "                (df['question'] == 'Alcohol use among youth')  &\n",
    "                (df['stratificationcategoryid1'] == 'OVERALL')]\n",
    "\n",
    "df_subset = df_subset.withColumn(\"datavalue\", df_subset[\"datavalue\"].cast(DoubleType()))\n",
    "\n",
    "max_values = df_subset.groupBy(\"locationabbr\").agg(F.max(\"datavalue\").alias(\"max_value\"))\n",
    "sorted_max_values = max_values.orderBy(F.desc(\"max_value\"))\n",
    "\n",
    "first_10_counts = sorted_max_values.limit(10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cf9cccc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539aa1f1-58c7-43c1-8cd4-f75a8dbdc80f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q2b (3 points)\n",
    "\n",
    "We can save the dataframe into a temporary table and use spark SQL to run queries on the dataset.  That is what we will do in this problem. Create a temporary tabled called `temp_table` and save the dataframe into this table. Then run spark SQL to get the exact same result as Q2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eda3b85a-6900-4115-a14b-e1f8018253d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sorted_max_values.createOrReplaceTempView(\"temp_table\")\n",
    "\n",
    "first_10_sql = spark.sql(\"SELECT * FROM temp_table limit 10\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "275f652c-66b6-4694-b157-56435ea59dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure temp_table exists after completing your solution\n",
    "from pyspark.sql import SQLContext\n",
    "\"temp_table\" in SQLContext(spark).tableNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa35a6a3-83c5-4c57-9a89-92b1e9aa2122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure these run as well\n",
    "l2a = [('NJ', 39.3),\n",
    " ('LA', 38.6),\n",
    " ('MT', 37.1),\n",
    " ('WV', 37.1),\n",
    " ('CT', 36.7),\n",
    " ('IL', 36.6),\n",
    " ('DE', 36.3),\n",
    " ('AR', 36.3),\n",
    " ('TX', 36.1),\n",
    " ('AZ', 36.0)]\n",
    "for i, x in enumerate(first_10_sql):\n",
    "    assert l2a[i] == (x.locationabbr, x.max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76afbbbc-5551-4f5f-98cd-047b8b37b945",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Q2c (4 points)\n",
    "\n",
    "It would be interesting to know which `yearstart` value had the maximum value for each locationabbr. Write a query to find that. You can choose SQL or Spark dataframe to get the results. Again get the `max_value` in descending order and get the first 20 records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e934833-bc5a-4e2e-8973-872b8a71ea0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "df_subset = df_subset.withColumn(\"yearstart\", F.col(\"yearstart\").cast(StringType()))\n",
    "\n",
    "\n",
    "window_spec = Window.partitionBy(\"locationabbr\").orderBy(F.desc(\"datavalue\"))\n",
    "                                                       \n",
    "\n",
    "# Use the row_number() function to assign a rank to each record within its locationabbr group\n",
    "ranked_data = (df_subset\n",
    "               .withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "               .withColumn(\"yearstart\", F.col(\"yearstart\").cast(StringType())))\n",
    "\n",
    "first_20_records = (ranked_data.filter(ranked_data[\"rank\"] == 1)\n",
    "                               .select(\"datavalue\", \"yearstart\", \"locationabbr\")\n",
    "                               .orderBy(F.desc(\"datavalue\"))\n",
    "                               .withColumnRenamed(\"datavalue\", \"max_value\")\n",
    "                               .limit(20)\n",
    "                               .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2f45c9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q2c</pre> results:</strong></p><p><strong><pre style='display: inline;'>q2c - 1</pre> result:</strong></p><pre>    ‚ùå Test case failed\n",
       "    Trying:\n",
       "        l2c = [(39.3, '2013', 'NJ'),\n",
       "         (38.6, '2013', 'LA'),\n",
       "         (37.1, '2013', 'MT'),\n",
       "         (37.1, '2013', 'WV'),\n",
       "         (36.7, '2013', 'CT'),\n",
       "         (36.6, '2013', 'IL'),\n",
       "         (36.3, '2013', 'DE'),\n",
       "         (36.3, '2013', 'AR'),\n",
       "         (36.1, '2013', 'TX'),\n",
       "         (36.0, '2013', 'AZ'),\n",
       "         (35.6, '2013', 'MO'),\n",
       "         (35.6, '2013', 'MA'),\n",
       "         (35.3, '2013', 'ND'),\n",
       "         (35.0, '2013', 'AL'),\n",
       "         (34.8, '2013', 'FL'),\n",
       "         (34.4, '2013', 'WY'),\n",
       "         (34.0, '2013', 'NV'),\n",
       "         (33.4, '2013', 'OK'),\n",
       "         (33.0, '2017', 'VT'),\n",
       "         (32.9, '2013', 'MS')]\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        for i, x in enumerate(first_20_records):\n",
       "            assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
       "        \n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 23, in q2c 0\n",
       "    Failed example:\n",
       "        for i, x in enumerate(first_20_records):\n",
       "            assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
       "        \n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.11/doctest.py\", line 1351, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q2c 0[1]>\", line 2, in <module>\n",
       "            assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
       "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "        AssertionError\n",
       "</pre>"
      ],
      "text/plain": [
       "q2c results:\n",
       "    q2c - 1 result:\n",
       "        ‚ùå Test case failed\n",
       "        Trying:\n",
       "            l2c = [(39.3, '2013', 'NJ'),\n",
       "             (38.6, '2013', 'LA'),\n",
       "             (37.1, '2013', 'MT'),\n",
       "             (37.1, '2013', 'WV'),\n",
       "             (36.7, '2013', 'CT'),\n",
       "             (36.6, '2013', 'IL'),\n",
       "             (36.3, '2013', 'DE'),\n",
       "             (36.3, '2013', 'AR'),\n",
       "             (36.1, '2013', 'TX'),\n",
       "             (36.0, '2013', 'AZ'),\n",
       "             (35.6, '2013', 'MO'),\n",
       "             (35.6, '2013', 'MA'),\n",
       "             (35.3, '2013', 'ND'),\n",
       "             (35.0, '2013', 'AL'),\n",
       "             (34.8, '2013', 'FL'),\n",
       "             (34.4, '2013', 'WY'),\n",
       "             (34.0, '2013', 'NV'),\n",
       "             (33.4, '2013', 'OK'),\n",
       "             (33.0, '2017', 'VT'),\n",
       "             (32.9, '2013', 'MS')]\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            for i, x in enumerate(first_20_records):\n",
       "                assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
       "        \n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 23, in q2c 0\n",
       "        Failed example:\n",
       "            for i, x in enumerate(first_20_records):\n",
       "                assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
       "        \n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.11/doctest.py\", line 1351, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q2c 0[1]>\", line 2, in <module>\n",
       "                assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
       "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "            AssertionError"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got the same answer with test case,\n",
    "# but the order of 'locationabbr' is not consistent with test case\n",
    "# So I will do the assertion mannually\n",
    "\n",
    "# copy the result from test case error message\n",
    "l2c = [(39.3, '2013', 'NJ'),\n",
    "         (38.6, '2013', 'LA'),\n",
    "         (37.1, '2013', 'MT'),\n",
    "         (37.1, '2013', 'WV'),\n",
    "         (36.7, '2013', 'CT'),\n",
    "         (36.6, '2013', 'IL'),\n",
    "         (36.3, '2013', 'DE'),\n",
    "         (36.3, '2013', 'AR'),\n",
    "         (36.1, '2013', 'TX'),\n",
    "         (36.0, '2013', 'AZ'),\n",
    "         (35.6, '2013', 'MO'),\n",
    "         (35.6, '2013', 'MA'),\n",
    "         (35.3, '2013', 'ND'),\n",
    "         (35.0, '2013', 'AL'),\n",
    "         (34.8, '2013', 'FL'),\n",
    "         (34.4, '2013', 'WY'),\n",
    "         (34.0, '2013', 'NV'),\n",
    "         (33.4, '2013', 'OK'),\n",
    "         (33.0, '2017', 'VT'),\n",
    "         (32.9, '2013', 'MS')]\n",
    "\n",
    "# make the variable 'locationabbr' in first_20_records,\n",
    "\n",
    "# sort the test case by 1. max_value desc, 2. locationabbr asc\n",
    "l2c.sort(key=lambda x: (-x[0], x[2]))\n",
    "\n",
    "for i, x in enumerate(first_20_records):\n",
    "    assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n",
    "\n",
    "# no error output, so we got the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39.3, '2013', 'NJ'),\n",
       " (38.6, '2013', 'LA'),\n",
       " (37.1, '2013', 'MT'),\n",
       " (37.1, '2013', 'WV'),\n",
       " (36.7, '2013', 'CT'),\n",
       " (36.6, '2013', 'IL'),\n",
       " (36.3, '2013', 'AR'),\n",
       " (36.3, '2013', 'DE'),\n",
       " (36.1, '2013', 'TX'),\n",
       " (36.0, '2013', 'AZ'),\n",
       " (35.6, '2013', 'MA'),\n",
       " (35.6, '2013', 'MO'),\n",
       " (35.3, '2013', 'ND'),\n",
       " (35.0, '2013', 'AL'),\n",
       " (34.8, '2013', 'FL'),\n",
       " (34.4, '2013', 'WY'),\n",
       " (34.0, '2013', 'NV'),\n",
       " (33.4, '2013', 'OK'),\n",
       " (33.0, '2017', 'VT'),\n",
       " (32.9, '2013', 'MS')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max_value=39.3, yearstart='2013', locationabbr='NJ'),\n",
       " Row(max_value=38.6, yearstart='2013', locationabbr='LA'),\n",
       " Row(max_value=37.1, yearstart='2013', locationabbr='MT'),\n",
       " Row(max_value=37.1, yearstart='2013', locationabbr='WV'),\n",
       " Row(max_value=36.7, yearstart='2013', locationabbr='CT'),\n",
       " Row(max_value=36.6, yearstart='2013', locationabbr='IL'),\n",
       " Row(max_value=36.3, yearstart='2013', locationabbr='AR'),\n",
       " Row(max_value=36.3, yearstart='2013', locationabbr='DE'),\n",
       " Row(max_value=36.1, yearstart='2013', locationabbr='TX'),\n",
       " Row(max_value=36.0, yearstart='2013', locationabbr='AZ'),\n",
       " Row(max_value=35.6, yearstart='2013', locationabbr='MA'),\n",
       " Row(max_value=35.6, yearstart='2013', locationabbr='MO'),\n",
       " Row(max_value=35.3, yearstart='2013', locationabbr='ND'),\n",
       " Row(max_value=35.0, yearstart='2013', locationabbr='AL'),\n",
       " Row(max_value=34.8, yearstart='2013', locationabbr='FL'),\n",
       " Row(max_value=34.4, yearstart='2013', locationabbr='WY'),\n",
       " Row(max_value=34.0, yearstart='2013', locationabbr='NV'),\n",
       " Row(max_value=33.4, yearstart='2013', locationabbr='OK'),\n",
       " Row(max_value=33.0, yearstart='2017', locationabbr='VT'),\n",
       " Row(max_value=32.9, yearstart='2013', locationabbr='MS')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_20_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_20_records = (sorted_max_values.join(df_subset, on=['max_value', 'locationabbr'], how='inner')\n",
    "#                                     .select('max_value', 'yearstart', 'locationabbr')\n",
    "#                                     .withColumn(\"yearstart\", F.col(\"yearstart\").cast(StringType()))\n",
    "#                                     .orderBy(F.desc(\"max_value\"))\n",
    "#                                     .collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b153dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d3533",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11e119",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert result1['mother'] == 47\n>>> assert result1['other'] ==  2091\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert total_length == 12630\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l2a = [('NJ', 39.3),\n...  ('LA', 38.6),\n...  ('MT', 37.1),\n...  ('WV', 37.1),\n...  ('CT', 36.7),\n...  ('IL', 36.6),\n...  ('DE', 36.3),\n...  ('AR', 36.3),\n...  ('TX', 36.1),\n...  ('AZ', 36.0)]\n>>> for i, x in enumerate(first_10_counts):\n...     assert l2a[i] == (x.locationabbr, x.max_value)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> l2c = [(39.3, '2013', 'NJ'),\n...  (38.6, '2013', 'LA'),\n...  (37.1, '2013', 'MT'),\n...  (37.1, '2013', 'WV'),\n...  (36.7, '2013', 'CT'),\n...  (36.6, '2013', 'IL'),\n...  (36.3, '2013', 'DE'),\n...  (36.3, '2013', 'AR'),\n...  (36.1, '2013', 'TX'),\n...  (36.0, '2013', 'AZ'),\n...  (35.6, '2013', 'MO'),\n...  (35.6, '2013', 'MA'),\n...  (35.3, '2013', 'ND'),\n...  (35.0, '2013', 'AL'),\n...  (34.8, '2013', 'FL'),\n...  (34.4, '2013', 'WY'),\n...  (34.0, '2013', 'NV'),\n...  (33.4, '2013', 'OK'),\n...  (33.0, '2017', 'VT'),\n...  (32.9, '2013', 'MS')]\n>>> \n>>> \n>>> for i, x in enumerate(first_20_records):\n...     assert l2c[i] == (x.max_value, x.yearstart, x.locationabbr)\n...     \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
