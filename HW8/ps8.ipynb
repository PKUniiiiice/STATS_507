{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"ps8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA on crime in Detroit\n",
    "This data corresponds to the open dataset provided by data.detroitmi.gov\n",
    "https://data.detroitmi.gov/datasets/detroitmi::rms-crime-incidents/about\n",
    "\n",
    "In this assignment, you will perform Exploratory Data Analytics on the given dataset. To score full points, you have to provide a conclusion with your insights after exploring the dataset with specific recommendation on what folks could do to avoid being a crime victim in Detroit. Assignments will no conclusion will lose a point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1\n",
    "Load the dataset from crime_data.csv file given with this file into a dataframe variable named `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./crime_data.csv\", header=0,\n",
    "                  dtype={\"report_number\": str, \"arrest_charge\": str,\n",
    "                         \"scout_car_area\": str, \"precinct\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2\n",
    "Get all the column names of the dataframe that has 'offense' mentioned anywhere in the name.\n",
    "Do not hard code the values. You have to derive the values using a suitable coding expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3\n",
    "Put the name of the only column that has some null values in cols_with_null variable. Here again you have to derive the column name with suitable expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This has only one hidden test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_with_null = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4\n",
    "Look into the offense_description column. \n",
    "Clean up the offense descriptions by removing the `-` and getting rid of any text after the `-` (along with empty spaces around the word) and then count the number of unique offense descriptions in this dataset.\n",
    "Assign the number of unique offense description types after cleaning to the variable `count_of_unique_offense_desc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "count_of_unique_offense_desc = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Plot the distribution of the 10 most common offense category  and 10 least common offense categories\n",
    "with appropriate titles for 'x' and 'y' axis in the same figure. To ensure all your tests pass properly, create a figure object  with two axes sub plots `ax`. Assign the `ax[0]` to 10 largest and `ax[1]` to 10 smallest counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fix, ax = None, None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Question 6\n",
    "Write a query to count all the offenses that has the keyword `larceny` in the offense description and assign that value to a variable called `total_larcenies_in_description`. Also get the total number of records that have `larceny` in the offense_category and check if the two counts match. Answer if the counts match or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "total_larcenies = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 7\n",
    "Which day of the week has the maximum number of offenses? Write a query to find that and assign the result to `week_day_with_max_offenses`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "week_day_with_max_offenses = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 8\n",
    "Segment the 24 hours into \n",
    "* night from 12 midnight to 5 am\n",
    "* morning from 5:01 am to 12 noon\n",
    "* afternoon from 12.01 noon to 5 pm\n",
    "* evening from 5.01 pm to 12 am\n",
    "\n",
    "And then show the total crimes for each day of the week and the day segment counts in a suitable chart. \n",
    "Hint: You could use one of the seaborn Facet charts for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 9\n",
    "Answer any other questions that might have to come to your mind after working on this dataset for this long. \n",
    "You have to show at least 3 different charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 10\n",
    "Since we have lat/lon information in this dataset, show a suitable geo spatial display of crime locations.\n",
    "\n",
    "Hint: you could use Plotly Choropleth: https://plotly.com/python/scatter-plots-on-maps/#north-american-precipitation-map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload this .zip file to Gradescope for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert df is not None\n>>> assert isinstance(df, pd.core.frame.DataFrame)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert all(cols == ['offense_description', 'offense_category', 'state_offense_code'])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert count_of_unique_offense_desc == 98\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert str(ax[0].get_xticklabels()).find('ASSAULT') != -1\n>>> assert str(ax[0].get_xticklabels()).find('LARCENY') != -1\n>>> assert str(ax[0].get_xticklabels()).find('DAMAGE TO PROPERTY') != -1\n>>> assert str(ax[0].get_xticklabels()).find('AGGRAVATED ASSAULT') != -1\n>>> assert str(ax[0].get_xticklabels()).find('STOLEN VEHICLE') != -1\n>>> assert str(ax[0].get_xticklabels()).find('FRAUD') != -1\n>>> assert str(ax[0].get_xticklabels()).find('BURGLARY') != -1\n>>> assert str(ax[0].get_xticklabels()).find('WEAPONS OFFENSES') != -1\n>>> assert str(ax[0].get_xticklabels()).find('ROBBERY') != -1\n>>> assert str(ax[0].get_xticklabels()).find('STOLEN PROPERTY') != -1\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert str(ax[1].get_xticklabels()).find('GAMBLING') != -1\n>>> assert str(ax[1].get_xticklabels()).find('SOLICITATION') != -1\n>>> assert str(ax[1].get_xticklabels()).find('SEXUAL ASSAULT') != -1\n>>> assert str(ax[1].get_xticklabels()).find('JUSTIFIABLE HOMICIDE') != -1\n>>> assert str(ax[1].get_xticklabels()).find('EXTORTION') != -1\n>>> assert str(ax[1].get_xticklabels()).find('LIQUOR') != -1\n>>> assert str(ax[1].get_xticklabels()).find('KIDNAPPING') != -1\n>>> assert str(ax[1].get_xticklabels()).find('FORGERY') != -1\n>>> assert str(ax[1].get_xticklabels()).find('OTHER') != -1\n>>> assert str(ax[1].get_xticklabels()).find('DISORDERLY CONDUCT') != -1\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert week_day_with_max_offenses == 5\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
